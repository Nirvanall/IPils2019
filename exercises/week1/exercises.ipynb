{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 1 - What is an inverse problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix inversion\n",
    "\n",
    "We want to solve a system of linear equations $Ku = f$ with :\n",
    "\n",
    "1. $$K = \\left(\\begin{matrix} 1 & 2 \\\\ 2 & 1\\end{matrix}\\right), \\quad f = \\left(\\begin{matrix} 1 \\\\ 1 \\end{matrix}\\right),$$\n",
    "\n",
    "2. $$K = \\left(\\begin{matrix} 1 & 1 \\\\ 1 & 1.001\\end{matrix}\\right), \\quad f = \\left(\\begin{matrix} 1 \\\\ 1 \\end{matrix}\\right),$$\n",
    "\n",
    "3. $$K = \\left(\\begin{matrix} 1 & 1 \\\\ 2 & 1 \\\\ 2 & 2\\end{matrix}\\right), \\quad f = \\left(\\begin{matrix} 1 \\\\ 1 \\\\ 1\\end{matrix}\\right),$$\n",
    "\n",
    "4. $$K = \\left(\\begin{matrix} 1 & 1 \\\\ 2 & 1 \\\\ 2 & 2\\end{matrix}\\right), \\quad f = \\left(\\begin{matrix} 1 \\\\ 2 \\\\ 2\\end{matrix}\\right),$$\n",
    "\n",
    "5. $$K = \\left(\\begin{matrix} 1 & 2 & 1\\\\ 2 & 0 & 2\\end{matrix}\\right), \\quad f = \\left(\\begin{matrix} 1 \\\\ 1 \\end{matrix}\\right),$$\n",
    "\n",
    "6. $$K = \\left(\\begin{matrix} 1 & 0 \\\\ 0 & 0\\end{matrix}\\right), \\quad f = \\left(\\begin{matrix} 0 \\\\ 1 \\end{matrix}\\right),$$\n",
    "\n",
    "Is the system ill-posed? why? You can easily compute eigenvalues and vectors numerically, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The eigenvalues are: [ 3. -1.]\n",
      "The eigenvectors are: [0.70710678 0.70710678] [-0.70710678  0.70710678]\n"
     ]
    }
   ],
   "source": [
    "K = np.array([[1,2],[2,1]])\n",
    "f = np.array([1,1])\n",
    "\n",
    "l, V = np.linalg.eig(K)\n",
    "print(\"The eigenvalues are:\", l)\n",
    "print(\"The eigenvectors are:\",V[:,0], V[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix inversion II\n",
    "\n",
    "Given a symmetric, positive definite matrix $K \\in \\mathbb{R}^{n\\times n}$ we want to solve $Ku = f$. Such a matrix can be decomposed as\n",
    "$$K = \\sum_{i=1}^n \\lambda_i k_ik_i^T,$$\n",
    "where $\\lambda_1\\geq \\lambda_2 \\geq \\ldots \\geq \\lambda_n > 0$ are the eigenvalues and $k_i$ denote the eigenvectors. Such matrix has an inverse given by \n",
    "$$K^{-1} = \\sum_{i=1}^n \\lambda_i^{-1} k_ik_i^T.$$\n",
    "\n",
    "To study the well-posedness of the equation we want to bound the *backward error* $\\|u - u^\\delta\\|_2$ in terms of the *forward error* $\\|f - f^{\\delta}\\|_2$ where $Ku = f$ and $Ku^{\\delta} = f^\\delta$.\n",
    "\n",
    "1. Show that $$\\|u - u^\\delta\\|_2 \\leq \\lambda_n^{-1} \\|f - f^{\\delta}\\|_2.$$\n",
    "2. Show that the *relative error* is bounded by\n",
    "$$\\frac{\\|u - u^\\delta\\|_2}{\\|u\\|_2} \\leq \\lambda_1\\lambda_n^{-1} \\frac{\\|f - f^{\\delta}\\|_2}{\\|f\\|_2}.$$\n",
    "3. Compute the condition numbers for the matrices 1, 2 and 6 in the previous excercise; what do you notice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differentiation\n",
    "\n",
    "We are given the following inverse problem\n",
    "\n",
    "$$f(x) = \\int_0^{x'} u(x')\\mathrm{d}x',\\quad x' \\in [0,1].$$\n",
    "\n",
    "It is readily verified that we can find a (unique) solution by differentiation: $u(x) = f'(x)$. To study well-posedness of the problem, we consider *noisy* measurements $f^{\\delta}(x) = f(x) + \\delta\\sin(k x /\\delta)$ for fixed  arbitrary $k$ and small $\\delta > 0$.\n",
    "\n",
    "1. Show that the *forward error* $f - f^{\\delta}$ is bounded in the $L^{\\infty}$ norm, in particular $\\|f - f^{\\delta}\\|_{L^{\\infty}([0,1])} = \\delta$.\n",
    "2. Show that the *backward error* $u - u^{\\delta}$ can be arbirarily large, even if $\\delta\\downarrow 0$: $\\|u - u^{\\delta}\\|_{L^{\\infty}([0,1])} = k$.\n",
    "\n",
    "This shows that the problem is *ill-conditioned*; a small forward error does not guarantee a small backward error, implying that the inverse map is not continuous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differentiation II\n",
    "\n",
    "The analysis in the previous exercise depends crucially on the type of noise we allow. If we assume that $n^{\\delta} = f - f^{\\delta}$ is bounded by $\\delta$ in a different norm, we can get a well-posed problem.\n",
    "\n",
    "1. Assuming that $\\|n^{\\delta}\\|_{C^1([0,1])} \\leq \\delta$, show that $\\|u - u^{\\delta}\\|_{L^{\\infty}([0,1])} \\rightarrow 0$ when $\\delta \\rightarrow 0$.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
