{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1:\n",
    "\n",
    "Consider a linear inverse problem\n",
    "$$\n",
    "Ku = f^{\\delta},\n",
    "$$\n",
    "with $f^{\\delta} = K\\overline u + \\epsilon$, where $\\epsilon$ is drawn from a normal distributed with zero mean and covariance $\\Sigma_{\\text{noise}}$ and $\\overline u$ is drawn from a normal distributed with mean $\\mu_{\\text{prior}}$ and covariance $\\Sigma_{\\text{prior}}$.\n",
    "\n",
    "Show that the posterior distribution is Gaussian with mean\n",
    "$$\n",
    "\\mu_{\\text{post}} = \\mu_{\\text{prior}} + \\left(K^T\\Sigma_{\\text{noise}}^{-1}K + \\Sigma_{\\text{prior}}^{-1}\\right)^{-1}K^T\\Sigma_{\\text{noise}}^{-1}(f - K\\mu_{\\text{prior}}),\n",
    "$$\n",
    "and covariance\n",
    "$$\n",
    "\\Sigma_{\\text{post}} = \\Sigma_{\\text{prior}} - \\Sigma_{\\text{prior}}K^T\\left(K\\Sigma_{\\text{prior}}K^T + \\Sigma_{\\text{noise}}\\right)^{-1}K\\Sigma_{\\text{prior}}.\n",
    "$$\n",
    "Hint: The [Binomial inverse theorem](https://en.wikipedia.org/wiki/Woodbury_matrix_identity#Binomial_inverse_theorem) may come in handy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2:\n",
    "Consider a linear inverse problem $Ku = f^{\\delta}$, where we assume that $f^{\\delta}$ follows a Poisson distribution with mean $\\overline f = K\\overline{u}$.\n",
    "\n",
    "* Show that the MAP estimate may be obtained by solving the following minimization problem\n",
    "$$\n",
    "\\min_u \\sum_i \\left(({K}u)_i - f_i^\\delta\\ln ({K}u)_i\\right).\n",
    "$$\n",
    "\n",
    "* Assuming that both $\\|f^{\\delta} - \\overline f\\|_2$ and $\\|u-\\overline u\\|_2$ are small, show that the log-likelihood function may be approximated as\n",
    "$$\n",
    "\\sum_i \\left(({K}u)_i - f_i^\\delta\\ln ({K}u)_i\\right) \\approx \\|Ku - f^{\\delta}\\|_{\\Sigma^{-1}}^2,\n",
    "$$\n",
    "where $\\Sigma$ is a diagonal matrix with elements $1/\\overline f_i$.\n",
    "\n",
    "* In practice, we would replace $\\overline f_i$ by $f_i^{\\delta}$ for the covariance and thus approximate the Poisson map estimate as a weighted least-squares MAP estimate. Explain why this quadratic approximation makes sense heuristically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3:\n",
    "Consider the inverse problem\n",
    "$$\n",
    "Ku = f^{\\delta},\n",
    "$$\n",
    "where\n",
    "$$Ku(x) = \\int_0^1 u(x')e^{-d(x-x')^2} \\mathrm{d}x',$$\n",
    "and\n",
    "$$\n",
    "f^{\\delta} = K\\overline{u} + \\epsilon.\n",
    "$$\n",
    "Generate $\\overline u \\in \\mathbb{R}^n$ as Gaussian random fields with mean zero and covariance\n",
    "$$\n",
    "\\Sigma_{ij} = \\exp\\left(-\\frac{|x_i-x_j|}{L}\\right),\n",
    "$$\n",
    "and Gaussian noise, $\\epsilon$, with zero mean and variance $\\sigma$.\n",
    "\n",
    "\n",
    "* For varying correlation length $L$ and noise level $\\sigma$, reconstruct the images using the regularized pseudo inverse of $K$. How well can you reconstruct? You can draw samples from the multivariate normal distribution using `numpy.random.multivariate_normal`\n",
    "\n",
    "* Compute the MAP estimate from\n",
    "$$\n",
    "\\min_{u} \\sigma^{-2}\\|Ku - f^{\\delta}\\|_2^2 + \\|u\\|_{\\Sigma^{-1}}^2.\n",
    "$$\n",
    "How well can you reconstruct now?\n",
    "\n",
    "* What happens if you use two different covariance matrices for generating and reconstructing $u$?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getK(n):\n",
    "    h = 1/n;\n",
    "    d = 1e3;\n",
    "    x = np.linspace(h/2,1-h/2,n)\n",
    "    xx,yy = np.meshgrid(x,x)\n",
    "    K = np.exp(-d*(xx-yy)**2)\n",
    "    \n",
    "    return K,x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "sigma = 1e-2\n",
    "L = 1\n",
    "\n",
    "K,x = getK(n)\n",
    "\n",
    "C = np.exp(-np.abs(np.outer(x,np.ones(n)) - np.outer(np.ones(n),x))/L)\n",
    "\n",
    "u = np.random.multivariate_normal(np.zeros(n),C)\n",
    "noise = sigma*np.random.randn(n)\n",
    "f = K@u + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
